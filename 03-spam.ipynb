{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n3lnWjvI83ix"
   },
   "source": [
    "# Filtado de mensajes spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del problema real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La recepción de publicidad no deseada a traves mensajes de texto usando SMS (Short Message Service) es un problema que afecta a muchos usuarios de teléfonos móviles. El problema radica en que los usuarios deben pagar por los mesajes recibidos, y por este motivo resulta muy importante que las compañías prestadoras del servicio puedan filtrar mensajes indeseados antes de enviarlos a su destinatario final. Los mensajes tienen una longitud máxima de 160 caracteres, por lo que el texto resulta poco para realizar la clasificación, en comparación con textos más largos (como los emails). Adicionalmente, los errores de digitación dificultan el proceso de detección automática."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del problema en términos de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tiene una muestra contiene 5574 mensajes en inglés, no codificados y clasificados como legítimos (ham) o spam (http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/). La información está almacenada en el archivo `datos/spam-sms.zip`.El problema en términos de los datos consiste en clasificar si un mensaje SMS es legítico o spam, a partir del análisis de las palabras que contiente, partiendo del supuesto de que ciertas palabras que son más frecuentes dependiendo del tipo de mensaje. Esto implica que en la fase de preparación de los datos se deben extraer las palabras que contiene cada mensaje para poder realizar el análsis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aproximaciones posibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, se desea comparar los resultados de un modelo de redes neuronales artificiales y otras técnicas estadísticas para realizar la clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requerimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usted debe:\n",
    "\n",
    "* Preprocesar los datos para representarlos usando bag-of-words.\n",
    "\n",
    "\n",
    "* Construir un modelo de regresión logística como punto base para la comparación con otros modelos más complejos.\n",
    "\n",
    "\n",
    "* Construir un modelo de redes neuronales artificiales. Asimismo, debe determinar el número de neuronas en la capa o capas ocultas.\n",
    "\n",
    "\n",
    "* Utiizar una técnica como crossvalidation u otra similar para establecer la robustez del modelo.\n",
    "\n",
    "\n",
    "* Presentar métricas de desempeño para establecer las bondades y falencias de cada clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import seed\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#Modelos\n",
    "import sklearn.neural_network\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/jdvelasq/datalabs/master/datasets/sms-spam.csv\",\n",
    "    sep = ',',\n",
    "    decimal = '.',\n",
    "    encoding='latin-1')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.type.value_counts().plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Aplicación de Stemmer\n",
    "\n",
    "Debido a la presencia de afijos morfológicos en las palabras, se debe hacer algo parecido a una traducción a una manera más\n",
    "compacta de la  palabra, esto nos deja los datos de una manera mas concisa. Se decidide usar la herramienta PorterStemmer \n",
    "de la librería sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point, crazy.. avail onli in b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar... joke wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri in 2 a wkli comp to win FA cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so earli hor... U c alreadi then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah I don't think he goe to usf, he live aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>freemsg hey there darl it' been 3 week' now an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>As per your request 'mell mell (oru minnaminun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>winner!! As a valu network custom you have bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>had your mobil 11 month or more? U R entitl to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                               text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...   \n",
       "6   ham  Even my brother is not like to speak with me. ...   \n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...   \n",
       "8  spam  WINNER!! As a valued network customer you have...   \n",
       "9  spam  Had your mobile 11 months or more? U R entitle...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  Go until jurong point, crazy.. avail onli in b...  \n",
       "1                        Ok lar... joke wif u oni...  \n",
       "2  free entri in 2 a wkli comp to win FA cup fina...  \n",
       "3  U dun say so earli hor... U c alreadi then say...  \n",
       "4  nah I don't think he goe to usf, he live aroun...  \n",
       "5  freemsg hey there darl it' been 3 week' now an...  \n",
       "6  even my brother is not like to speak with me. ...  \n",
       "7  As per your request 'mell mell (oru minnaminun...  \n",
       "8  winner!! As a valu network custom you have bee...  \n",
       "9  had your mobil 11 month or more? U R entitl to...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "data['stemmed'] = data.text.apply(lambda x: ' '.join([stemmer.stem(w) for w in x.split() ]))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words\n",
    "\n",
    "A continuación creamos un bag of words con la frecuencia de cad palabra en un mensaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5574, 1540)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(analyzer='word',lowercase=True,stop_words='english',binary=True,min_df=5)\n",
    "\n",
    "## Aplica la función al texto\n",
    "dtm = count_vect.fit_transform(data.stemmed)\n",
    "\n",
    "## Las filas contienen los mensajes y las clomunas los términos\n",
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1540"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = count_vect.get_feature_names()\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Org:  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "Mod:  avail bugi cine got great la onli point wat world\n",
      "\n",
      "Org:  Ok lar... Joking wif u oni...\n",
      "Mod:  joke lar ok wif\n",
      "\n",
      "Org:  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "Mod:  appli comp cup entri final free question rate receiv std text txt win wkli\n",
      "\n",
      "Org:  U dun say so early hor... U c already then say...\n",
      "Mod:  alreadi dun earli say\n",
      "\n",
      "Org:  Nah I don't think he goes to usf, he lives around here though\n",
      "Mod:  don goe live nah think usf\n",
      "\n",
      "Org:  FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, Â£1.50 to rcv\n",
      "Mod:  50 darl freemsg fun hey like ok send std week word xxx\n",
      "\n",
      "Org:  Even my brother is not like to speak with me. They treat me like aids patent.\n",
      "Mod:  brother like speak treat\n",
      "\n",
      "Org:  As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
      "Mod:  callers callertun copi friend ha press request set\n",
      "\n",
      "Org:  WINNER!! As a valued network customer you have been selected to receivea Â£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
      "Mod:  12 900 claim code custom hour network prize reward select valid valu winner\n",
      "\n",
      "Org:  Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
      "Mod:  11 camera colour entitl free latest mobil month updat\n",
      "\n",
      "Org:  I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\n",
      "Mod:  don gonna home soon stuff talk thi today tonight want\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def dtm2words(dtm, vocabulary, index):\n",
    "    as_list = dtm[index,:].toarray().tolist()\n",
    "    docs = []\n",
    "    for i in index:\n",
    "        k = [vocabulary[iword] for iword, ifreq in enumerate(as_list[i]) if ifreq > 0]\n",
    "        docs += [k]\n",
    "    return docs\n",
    "\n",
    "for i, x in enumerate(dtm2words(dtm, vocabulary, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])):\n",
    "    print('Org: ', data.text[i])\n",
    "    print('Mod: ', ' '.join(x))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de la Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño X: (5574, 1540)\n",
      "Tamaño y: (5574,)\n"
     ]
    }
   ],
   "source": [
    "data['type'][data['type']=='spam'] = 1\n",
    "data['type'][data['type']=='ham'] = 0\n",
    "X  = dtm\n",
    "y= np.array(data.type,dtype='int64')\n",
    "\n",
    "print(\"Las dimensiones de X:\",X.shape)\n",
    "print(\"Las dimensiones de y:\",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "Se decide aplicar la herramieta BernoulliNB de la librería sklearn siguiendo un ejemplo dado por el profesor en la\n",
    "documentación de sus cursos, se puede encontrar en el siguiente link:\n",
    "https://jdvelasq.github.io/courses/notebooks/sklearn/bayes/02-filtrado-de-mensajes-sms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Promedio: 0.9796719707127352\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## Se crea un clasificador Naive Bayes (NB)\n",
    "##\n",
    "search = BernoulliNB()\n",
    "\n",
    "##\n",
    "## Se entrena el clasificador\n",
    "##\n",
    "scores = cross_val_score(search, X, y, cv=5,scoring = 'precision')\n",
    "print('Precision Promedio:',np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística\n",
    "\n",
    "### Ajuste de parámetros\n",
    "\n",
    "Para la elección de los parámetros que nos dejen las mejores métricas(en este caso: precision) se decide usar la herramienta GridSearchCV de la librería sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "params = {'penalty': ['l1', 'l2'],'C': [0.001,0.01,0.1,1,10,100]}\n",
    "log_reg = LogisticRegression()\n",
    "search = GridSearchCV(log_reg, params,cv=5,scoring='precision')\n",
    "search.fit(X,y)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento y Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1198    0]\n",
      " [ 147   49]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "log_reg =  LogisticRegression(C=search.best_params_['C'],penalty =search.best_params_['penalty'] )\n",
    "scores = cross_val_score(log_reg, X, y, cv=5,scoring = 'precision')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "log_reg = log_reg.fit(X_train,y_train)\n",
    "y_predict = log_reg.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal\n",
    "### Selección de Capas Ocultas\n",
    "\n",
    "Por motivos de recursos a la hora del procesamiento y computo, primero vamos a buscar la distribución de las capas ocultas antes de hacer la busqueda de los demás parámetros. Se decide usar la herramienta GridSearchCV de la librería sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layer_sizes': (10,)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.neural_network\n",
    "params = {\"hidden_layer_sizes\": [(6,),(7,),(8,),(10,)]}\n",
    "nn = sklearn.neural_network.MLPRegressor()\n",
    "search = GridSearchCV(nn, params,cv=5)\n",
    "search.fit(X,y)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de Otros Parámetros\n",
    "Una vez sabiendo el número de capas ocultas, seguimos con la busqueda de los demás parámetros faltantes. Se decide usar la herramienta GridSearchCV de la librería sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'max_iter': 1000, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "params = {'hidden_layer_sizes': [(10,)],\n",
    "          'activation': ['logistic','identity','relu','tanh'], \n",
    "          'solver': ['sgd','adam','lbfgs'], 'alpha': [0.00005,0.0005,0.1],\n",
    "          'learning_rate':['invscaling','constant','adaptive'],\n",
    "          'max_iter' : [1000] }\n",
    "nn = sklearn.neural_network.MLPClassifier()\n",
    "search = GridSearchCV(nn, params,cv=5,scoring='precision')\n",
    "search.fit(X,y)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'activation': 'logistic', 'alpha': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate': 'invscaling', 'max_iter': 1000, 'solver': 'adam'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento  y Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.99258699481733\n",
      "[[1195    3]\n",
      " [  26  170]]\n"
     ]
    }
   ],
   "source": [
    "nn =  sklearn.neural_network.MLPClassifier(\n",
    "                hidden_layer_sizes = (10,), \n",
    "                activation = 'logistic', \n",
    "                solver = 'adam',     \n",
    "                alpha = 0.1,            \n",
    "                learning_rate = 'invscaling',\n",
    "                max_iter = 1000)\n",
    "\n",
    "scores = cross_val_score(nn, X, y, cv=5,scoring = 'precision')\n",
    "print(\"Precision: \",np.mean(scores))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "nn = nn.fit(X_train,y_train)\n",
    "y_predict = nn.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión \n",
    "\n",
    "Podemos ver que la métrica precisión de los modelos es muy alta por lo tanto es muy díficil inferir cual de los dos modelos se comporta mejor, por eso debemos mirar sus matrices de Confusión para poder tener mejores argumentos\n",
    "\n",
    "REGRESION | RED NEURONAL\n",
    ":--------:| :-------:\n",
    "VP: 1198  | VP: 1195\n",
    "VN:  147  | VN:  26\n",
    "FP: 0     | FP: 3 \n",
    "FN: 49    | FN: 170\n",
    "\n",
    "Vemos que la regresión se comporta mejor para los mensajes no considerados como spam, aún cuando en general la red neuronal se comporta mejor"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Copia de Untitled3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
